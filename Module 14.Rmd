---
title: "Basic Categorical Data Analysis and ANOVA"
author: "Maria C. Codlin"
date: "October 26, 2017"
output: html_document
---

```{r}
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/zombies.csv")
z <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
class(z$gender)
```
```{r}
summary(z$gender)
```

```{r}
plot(z$height ~ z$gender)
```

This immediately gives us a nice barplot. Note that if we’d try to use this command after loading in “gender” as character rather than factor data, R would have thrown an error. Always make sure your variables are in the right format!

Based on our plot, there indeed seems to be a difference in height between males and females. We can test this directly using linear regression (and, recall, we already know another way to test this, using z or t tests to compare means).

```{r}
m <- lm(data = z, height ~ gender)
summary(m)
```
If we take a look at the summary() of our model, m, we see the same kind of table of results we have seen before, but because the predictor variable in this case is a factor vector instead of a numeric vector, the coefficients are reported and interpreted a bit differently. The coefficient for the intercept, i.e., β0, reflects the estimate of the mean height for the first of our level variables.

```{r}
levels(z$gender)
```

The estimate for β1
 is reported as “genderMale” and the value for that coefficient, 4.0154, is the estimated difference in mean height associated with being a male. The regression equation is basically:

height = 65.5983 + 4.0154 x gender, with males assigned a gender value of 1 and females of 0.

In this case, the p value associated with the t statistic for β1
 is extremely low, so we conclude that “gender” has a significant effect on height.

We can easily relevel() what is the baseline group (this becomes much more useful as we get more categorical variables in our regressions). The result is very similar, but the sign of β1
 is changed.
 
```{r}
z$gender <- relevel(z$gender, ref = "Male")
m <- lm(data = z, height ~ gender)
summary(m)
```
```{r}
z$occupation <- "temp"
```

We can use the unique() or levels() function to list all of the different majors in our dataset. The latter does this alphabetically. The row() command returns an index of row numbers, which we can then use to recode “major” into our new variable.

```{r}
unique(z$major)
```


```{r}
levels(z$major)
```
```{r}
row(data.frame(levels(z$major)))
```
```{r}
z$occupation[row(data.frame(levels(z$major))) %in% c(1, 2, 3, 5, 6, 14, 15, 
    16, 18, 21, 23)] <- "natural science"
z$occupation[row(data.frame(levels(z$major))) %in% c(7, 8, 12, 17, 19, 22)] <- "logistics"
z$occupation[row(data.frame(levels(z$major))) %in% c(4, 18, 20)] <- "engineering"
z$occupation[row(data.frame(levels(z$major))) %in% c(9, 10, 11, 13, 24, 25, 
    26)] <- "other"
z$occupation <- as.factor(z$occupation)
levels(z$occupation)
```

```{r}
z$occupation <- relevel(z$occupation, ref = "natural science")
levels(z$occupation)
```
Again, we can plot our variable by group and run a multilevel linear regression. Each β
 estimate reflects the difference from the estimated mean for the reference level. The lm() function also returns the results of the global significance test of our model.
 
 
```{r}
plot(data = z, zombies_killed ~ occupation)

```
```{r}
m <- lm(data = z, zombies_killed ~ occupation)
summary(m)
```

```{r}
p <- 1 - pf(0.526, df1 = 3, df2 = 996)  # F test
p
```

One-Way ANOVA
Regression with a single categorical predictor run as we have just done above is exactly equivalent to a “one-way” or “one-factor” analysis of variance, or ANOVA. That is, ANOVA is just one type of special case of least squares regression.

We can thus run an ANOVA with one line in R. Compare the results presented in the summary() output table from an ANOVA with that from the global test reported in summary() from lm()


```{r}
m <- aov(data = z, zombies_killed ~ occupation)
summary(m)
```

```{r}
par(mfrow = c(2, 2))
plot(m)
```
The summary of the lm() model produces a different table for the same analysis. It shows the effect sizes for each coefficient and their standard errors, whereas the F statistic and omnibus p value given in the ANOVA table indicates that there are differences between at least some treatments, but we do not know where those differences occur. The summary from lm() shows the effects arranged as sequential contrasts (the default in R). The first row gives the mean of the first level of the first factor specified in the model. The following rows give differences from this mean for each subsequent factor level. Likewise the standard error in the first row is a standard error of a mean, while the entries in subsequent rows are standard errors of the differences between two means.

In general, in ANOVA and simple regression using a single categorical variable, we aim to test the H0
 that the means of a variable of interest do not differ among groups, i.e., that μ1
 = μ2
… μk
 are all equal. This is an extension of our comparison of two means that we did with z and t tests.

The basic linear model formulation for ANOVA is:



where:

μ
 is the grand population mean

βi
 is the deviation of the mean of treatment level i
 from the grand mean

ϵi,j
 is error variance of individual points from the grand mean

The assumptions of ANOVA, similar to those of simple regression, are:

that samples are independent and identically distributed

that the residuals ϵi,j
 are normally distributed

that within-group variances are similar across all groups (‘homoscedastic”)

The following assumption makes the interpretation of results from ANOVA more straightforward, but it is not strictly required.

Our experiment/observations have a balanced design (i.e., an equal number of cases in all groups). If this is violated, it ceases to be true that the total SS of our dataset = within SS + between SS, and then the calculations of MSE and F and our associated p values would be off.
CHALLENGE:

Load in the “gibbon-femurs.csv” dataset, which contains the lengths, in centimeters, of the femurs of 400 juvenile, subadult, and adult individuals gibbons. Use both ANOVA and simple linear regession to examine the relationship between age and femur length. Before beginning, make sure that you check for normality of observations within each group.

Is the omnibus test of the relationship between age category and femur length significant? Are femur lengths significantly different for juveniles versus subadults? Subadults versus adults? Juveniles versus adults? HINT: to test these bivariate options, you will need to relevel() your factors for simple linear regression.


```{r}
library(curl)
library(dplyr)
```
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/gibbon-femurs.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
d$age <- factor(d$age, levels = c("inf", "juv", "subadult", "adult"))  #this reorders the age levels so that they're in order
head(d)
```

```{r}
hist(d$femur.length)
qqnorm(d$femur.length)
```
```{r}
plot(data = d, femur.length ~ age)  # boxplot with medians
means <- summarise(group_by(d, age), mean(femur.length))  # calculate average by group
points(1:4, means$`mean(femur.length)`, pch = 4, cex = 1.5)  # add means to plot
```

```{r}
sds <- summarise(group_by(d, age), sd(femur.length))
max(sds$`sd(femur.length)`)/min(sds$`sd(femur.length)`)  # check that variances are roughly equal (ratio of max/min is <2)
```

```{r}
means.centered <- d$femur.length - means[as.numeric(d$age), 2]  # subtract relevant group mean from each data point
qqnorm(means.centered$`mean(femur.length)`)  # graphical tests for normality
```

```{r}
par(mfrow = c(2, 2))
hist(d$femur.length[d$age == "inf"], main = "inf")
qqnorm(d$femur.length[d$age == "inf"])
hist(d$femur.length[d$age == "juv"], main = "juv")
qqnorm(d$femur.length[d$age == "juv"])
```

```{r}
hist(d$femur.length[d$age == "subadult"], main = "subadult")
qqnorm(d$femur.length[d$age == "subadult"])
hist(d$femur.length[d$age == "adult"], main = "adult")
qqnorm(d$femur.length[d$age == "adult"])
```

```{r}
par(mfrow = c(1, 1))
plot(data = d, femur.length ~ age)
```

```{r}
m <- aov(data = d, femur.length ~ age)  # femur length related to age
summary(m)
```

```{r}
m <- lm(data = d, femur.length ~ age)
summary(m)
```

